# General Info

This repo contains various python scripts I wrote as a research assistant to automate data collection from public sources. They include the following:

## 1. Scraping Carmax Addresses 
This script uses BeautifulSoup to scrape all CarMax dealership locations found on CarMax's website. Information about CarMax's dealership locations could answer many interesting questions. For instance, does the introduction of CarMax dealers induce other autolenders in the same regional market to extend credit more aggressively?               
    
## 2. Scraping County Codes from FFIEC:
This script uses Selenium to automate the process of typing in the address of a location to find the county code (FIPS) from the Federal Financial Institutions Examination Council's (FFIEC) geocoded mapping system. 

## 3. Scraping News about Stock Repurchases from Factiva:
These scripts use Selenium to automate the process of searching for articles/newswires within a specific time range on Factiva and saving relevant text files. 
I wrote this as an RA for a project focusing on firm equity repurchase/buyback announcements to measure the impact it has on their stock prices.
 
